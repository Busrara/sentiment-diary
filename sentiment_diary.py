# -*- coding: utf-8 -*-
"""Welcome To Colab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb
"""

import matplotlib.pyplot as plt
from wordcloud import WordCloud
from collections import Counter
import pandas as pd
from transformers import pipeline
from datetime import datetime
import nltk
from nltk.corpus import stopwords
import numpy as np

# Download NLTK stopwords
nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

# Sample journal entries
journal_entries = [
    {"date": "2025-04-14", "entry": "Today was a pretty good day overall. I woke up feeling energized and ready to tackle the tasks ahead. I spent some quality time with my family, which made me feel really happy. I was able to finish some work that had been on my to-do list for a while, and that felt rewarding."},
    {"date": "2025-04-15", "entry": "I had a tough day today. Work was stressful, and I had a disagreement with a colleague. I felt a bit down afterward, like I couldn’t shake off the tension. I tried to distract myself with some hobbies, but I couldn’t fully get rid of the negative feelings from the argument."},
    {"date": "2025-04-16", "entry": "Today was much better! I woke up feeling excited because I had planned to go for a walk in the park later in the day. It was a beautiful day, and being outside really lifted my spirits. I also caught up with a close friend, and our conversation made me feel energized and happy."},
    {"date": "2025-04-17", "entry": "I felt a bit tired today. It’s been a busy week, and I didn’t get enough rest last night. Still, I managed to get a lot of work done. Despite feeling tired, I tried to stay positive and focused, knowing that tomorrow will be better. Overall, it wasn’t a bad day, just a bit tiring."},
    {"date": "2025-04-18", "entry": "Today was frustrating. There were a lot of setbacks at work, and I felt like everything was going wrong. I had an argument with my manager, which made me feel angry and helpless. I tried to calm down in the evening, but I couldn’t shake the feeling of frustration."},
    {"date": "2025-04-19", "entry": "What a great day! I am grateful for today! I spent most of the day outdoors, enjoying the sunshine and fresh air. I went to the beach with some friends, and we had a great time swimming and chatting. It felt so freeing to disconnect from work and just be in the moment. I’m feeling incredibly grateful and content right now."},
    {"date": "2025-04-20", "entry": "Today was all about relaxation. I took a long walk by the lake to feel energized, meditated for a while, and then spent the afternoon reading. I’ve been feeling really peaceful and grateful lately, and I think today’s quiet moments just reinforced that. I’m looking forward to the week ahead, but for now, I’m enjoying this sense of tranquility."}
]

# Sentiment analysis setup using HuggingFace's transformers pipeline
sentiment_analyzer = pipeline("sentiment-analysis")

# Analyze sentiment for each entry
for entry in journal_entries:
  sentiment = sentiment_analyzer(entry['entry'])[0]
  entry['sentiment'] = sentiment['label']
  entry['confidence'] = sentiment['score']

# Create sentiment over time (positive vs. negative trend)
dates = [entry['date'] for entry in journal_entries]
sentiments = [entry['sentiment'] for entry in journal_entries]

# Convert the dates to datetime objects for easier manipulation
dates = [datetime.strptime(date, "%Y-%m-%d") for date in dates]

# Count the occurrences of positive and negative sentiments
positive_days = sum(1 for sentiment in sentiments if sentiment == "POSITIVE")
negative_days = sum(1 for sentiment in sentiments if sentiment == "NEGATIVE")

# Weekly mood summary (based on sentiment)
weekly_summary =  {
    'week': str(dates[0].strftime('%Y-%m-%d')) + " - " + str(dates[-1].strftime('%Y-%m-%d')),
    'summary': 'More positive' if positive_days > negative_days else 'More negative'
}

# Create a DataFrame for the weekly summary
weekly_summary_df = pd.DataFrame([weekly_summary])

# Print weekly summary for review
print(weekly_summary_df)


# Emotional words list (can be expanded)
emotion_words = ['happy', 'joy', 'excited', 'angry', 'sad', 'frustrated', 'grateful', 'calm', 'peaceful', 'tired', 'stressed', 'nervous', 'relaxed', 'hopeless', 'content', 'energized', 'down', 'motivated']

# Remove stopwords and focus on emotional words only
text = " ".join([entry["entry"] for entry in journal_entries])

# Tokenize the text and filter out stopwords and non-emotional words
tokens = text.split()
filtered_tokens = [word.lower() for word in tokens if word.lower() not in stop_words and word.lower() in emotion_words]

# Count the occurrences of emotional words
word_counts = Counter(filtered_tokens)

# Create the word cloud using the filtered emotional word counts
wordcloud = WordCloud(
    width = 800,
    height = 800,
    background_color = 'white',
    max_words = 200,
    contour_width = 3,
    contour_color = 'black',
    max_font_size = 100,
    min_font_size = 10,
    random_state = 42,
    relative_scaling = 0.5,
    normalize_plurals = False,
).generate_from_frequencies(word_counts)


# Display the word cloud
plt.figure(figsize=(10, 10))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.show()

# Save the wordcloud to a file
wordcloud.to_file("emotion_priority_wordcloud.png")

# Save the weekly summary as a CSV for future reference
weekly_summary_df.to_csv('weekly_summary.csv', index=False)

# Save the sentiment analysis results in a CSV for review
sentiment_df = pd.DataFrame(journal_entries)
sentiment_df.to_csv('sentiment_analysis_results.csv', index=False)